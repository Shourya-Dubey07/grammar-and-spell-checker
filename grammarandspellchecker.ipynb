{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "409738f6-eaf3-4693-94da-f95fab8e4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from itertools import permutations\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f5d8aa9e-1a19-42ae-bd61-152b1cd97fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads a list of words from a file.\n",
    "def load_words(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            words = [word.strip().lower() for word in f]\n",
    "        return words\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filepath}' not found.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b7fff312-f865-40a0-9ee5-eb5b58ff62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads a corpus of text from a file.\n",
    "def load_corpus(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            corpus = f.read()\n",
    "        return corpus\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filepath}' not found.\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9206597b-698c-4133-a9b2-640ba3191741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables from respective text files.\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "word_list = load_words(\"words.txt\")\n",
    "corpus = load_corpus(\"corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa179f7f-18fe-4b58-a3ee-b69395c01481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counts bigram frequencies in a corpus and loads it into a dictionary[bigram:frequency].\n",
    "def count_bigrams(corpus):\n",
    "    corpus = re.sub(r'[^\\w\\s]', ' ', corpus).lower()\n",
    "    words = corpus.split()\n",
    "    bigram_counts = defaultdict(int)\n",
    "    for i in range(len(words) - 1):\n",
    "        bigram = (words[i], words[i + 1])\n",
    "        bigram_counts[bigram] += 1\n",
    "    return bigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7082d6a3-7974-4c2f-b375-b517d51eaca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates total number of bigrams and bigram probabilities of each bigram and loads it into a dictionary[bigram:probability].\n",
    "def calculate_bigram_probabilities(bigram_counts):\n",
    "    total_bigrams = sum(bigram_counts.values())\n",
    "    bigram_probabilities = {}\n",
    "    for bigram, count in bigram_counts.items():\n",
    "        bigram_probabilities[bigram] = count / total_bigrams\n",
    "    return bigram_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08e9f9e4-1f42-4610-934b-badfbf6a2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates the Levenshtein distance between two strings.\n",
    "def levenshtein_distance(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2459e153-82ae-41a1-94c4-76ff28014a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks if a word is in the dictionary and suggests corrections using levenshtein distance.\n",
    "def spell_check(word, word_list, max_distance=2):\n",
    "    word = word.lower()\n",
    "    if word in word_list:\n",
    "        return word, []\n",
    "    suggestions = []\n",
    "    for w in word_list:\n",
    "        distance = levenshtein_distance(word, w)\n",
    "        if distance <= max_distance:\n",
    "            suggestions.append((w, distance))\n",
    "    suggestions.sort(key=lambda x: x[1])\n",
    "    return word, [s[0] for s in suggestions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f7c3183-3c4a-466f-815d-7f83ba2ac0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contextual spell check using bigram probabilities.\n",
    "def contextual_spell_check(sentence, word_list, bigram_probabilities, max_distance=2):\n",
    "    doc = nlp(sentence)\n",
    "    words = [token.text for token in doc]\n",
    "    corrected_words = []\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if word.lower() in word_list:\n",
    "            corrected_words.append(word)\n",
    "            continue\n",
    "\n",
    "        _, suggestions = spell_check(word, word_list, max_distance)\n",
    "\n",
    "        if not suggestions:\n",
    "            corrected_words.append(word)\n",
    "            continue\n",
    "\n",
    "        best_suggestion = suggestions[0]\n",
    "\n",
    "        if i > 0:\n",
    "            best_prob = 0\n",
    "            for suggestion in suggestions:\n",
    "                bigram = (words[i - 1].lower(), suggestion.lower())\n",
    "                prob = bigram_probabilities.get(bigram, 0.000000000000001)\n",
    "                if prob > best_prob:\n",
    "                    best_prob = prob\n",
    "                    best_suggestion = suggestion\n",
    "\n",
    "        corrected_words.append(best_suggestion)\n",
    "\n",
    "    return \" \".join(corrected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "92fb767f-5c4a-46fd-b73d-0f6705fa74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grammar productions.\n",
    "grammar_str = f\"\"\"\n",
    "    S -> NP VP | S Conj S | S PP\n",
    "    NP -> Det N | Pronoun\n",
    "    VP -> V | V NP | Be Adj\n",
    "    PP -> P NP\n",
    "    Conj -> 'and'\n",
    "    P -> 'with'\n",
    "    Det -> 'a' | 'his' | 'my'\n",
    "    N -> 'violin' | 'dog' | 'microscope' | 'garden' | 'tail'\n",
    "    V -> 'have' | 'has' | 'wags' | 'plays' | 'visits'\n",
    "    Adj -> 'cute' | 'happy'\n",
    "    Pronoun -> 'I' | 'He' | 'he' | 'They'\n",
    "    Be -> 'is' | 'am'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c8ac123f-c05c-4c8c-b3ba-720c4a13d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks and corrects grammar by rearranging words using the production rules.\n",
    "def check_and_correct_grammar(sentence, grammar_str):\n",
    "    try:\n",
    "        grammar = nltk.CFG.fromstring(grammar_str)\n",
    "        parser = nltk.ChartParser(grammar)\n",
    "        tokens = sentence.split()\n",
    "\n",
    "        for tree in parser.parse(tokens):\n",
    "            print(\"Grammatically correct:\")\n",
    "            tree.pretty_print()\n",
    "            return True, tree, sentence\n",
    "\n",
    "        print(\"Grammatically incorrect.\")\n",
    "\n",
    "        corrected_sentence = rearrange_words(tokens, grammar)\n",
    "        if corrected_sentence:\n",
    "            print(f\"Corrected sentence: {corrected_sentence}\")\n",
    "            tokens1 = corrected_sentence.split()\n",
    "            for tree in parser.parse(tokens1):\n",
    "                tree.pretty_print()\n",
    "            return False, None, corrected_sentence\n",
    "        else:\n",
    "            print(\"Unable to correct sentence by rearranging.\")\n",
    "            return False, None, sentence\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False, None, sentence\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return False, None, sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a659564e-570d-4ef2-a194-4a15c3ffbf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempts to rearrange words to match the grammar.\n",
    "def rearrange_words(tokens, grammar):\n",
    "\n",
    "    for perm in permutations(tokens):\n",
    "        try:\n",
    "            parser = nltk.ChartParser(grammar)\n",
    "            for tree in parser.parse(perm):\n",
    "                return \" \".join(perm)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c8d8b6a9-643f-4c82-949c-5b31d34ebafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate bigram frequency and probability.\n",
    "if not word_list or not corpus:\n",
    "    exit()\n",
    "bigram_counts = count_bigrams(corpus)\n",
    "bigram_probabilities = calculate_bigram_probabilities(bigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fa651804-d249-4667-94d3-0a8e74c2ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correct the inputted paragraph.\n",
    "def correct_paragraph(paragraph, word_list, bigram_probabilities, contextual_spell_check):\n",
    "    \"\"\"Corrects a paragraph by processing each sentence.\"\"\"\n",
    "    sentences = nltk.sent_tokenize(paragraph)\n",
    "    corrected_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        punctuation = []\n",
    "        sentence_no_punct = sentence\n",
    "        for match in re.finditer(r'[^\\w\\s]', sentence):\n",
    "            punctuation.append((match.group(0), match.start()))\n",
    "            sentence_no_punct = sentence_no_punct.replace(match.group(0), \"\")\n",
    "            sentence = sentence_no_punct\n",
    "        partially_corrected_sentence = contextual_spell_check(sentence, word_list, bigram_probabilities)\n",
    "        print(f\"\\nChecking sentence: '{partially_corrected_sentence}'\")\n",
    "        is_correct, tree, corrected_sentence = check_and_correct_grammar(partially_corrected_sentence, grammar_str)\n",
    "        offset = 1\n",
    "        for char, pos in punctuation:\n",
    "            corrected_sentence = corrected_sentence[:pos + offset] + char + corrected_sentence[pos + offset:]\n",
    "            offset += 1\n",
    "        corrected_sentences.append(corrected_sentence)\n",
    "\n",
    "    corrected_paragraph = \" \".join(corrected_sentences)\n",
    "    return corrected_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6d78cb94-43f2-4f01-838f-8027f607ff89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a paragraph:  I a have dog. He his tael wags. He is cuute and he plays.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking sentence: 'I a have dog'\n",
      "Grammatically incorrect.\n",
      "Corrected sentence: I have a dog\n",
      "              S             \n",
      "    __________|___           \n",
      "   |              VP        \n",
      "   |      ________|___       \n",
      "   NP    |            NP    \n",
      "   |     |         ___|___   \n",
      "Pronoun  V       Det      N \n",
      "   |     |        |       |  \n",
      "   I    have      a      dog\n",
      "\n",
      "\n",
      "Checking sentence: 'He his tail wags'\n",
      "Grammatically incorrect.\n",
      "Corrected sentence: He wags his tail\n",
      "              S              \n",
      "    __________|___            \n",
      "   |              VP         \n",
      "   |      ________|___        \n",
      "   NP    |            NP     \n",
      "   |     |         ___|___    \n",
      "Pronoun  V       Det      N  \n",
      "   |     |        |       |   \n",
      "   He   wags     his     tail\n",
      "\n",
      "\n",
      "Checking sentence: 'He is cute and he plays'\n",
      "Grammatically correct:\n",
      "                 S                         \n",
      "          _______|_________________         \n",
      "         S            |            S       \n",
      "    _____|___         |       _____|____    \n",
      "   NP        VP       |      NP         VP \n",
      "   |      ___|___     |      |          |   \n",
      "Pronoun  Be     Adj  Conj Pronoun       V  \n",
      "   |     |       |    |      |          |   \n",
      "   He    is     cute and     he       plays\n",
      "\n",
      "Corrected paragraph: I have a dog. He wags his tail. He is cute and he plays.\n"
     ]
    }
   ],
   "source": [
    "#Get input.\n",
    "paragraph = input(\"Enter a paragraph: \")\n",
    "corrected_paragraph = correct_paragraph(paragraph, word_list, bigram_probabilities, contextual_spell_check)\n",
    "print(f\"Corrected paragraph: {corrected_paragraph}\")\n",
    "#Sample Input: I a have dog. He his tael wags. He is cuute and he plays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "59efc74d-0831-48a7-b225-58839a54f31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking sentence: 'They have a microscope'\n",
      "Grammatically correct:\n",
      "              S                    \n",
      "    __________|___                  \n",
      "   |              VP               \n",
      "   |      ________|___              \n",
      "   NP    |            NP           \n",
      "   |     |         ___|______       \n",
      "Pronoun  V       Det         N     \n",
      "   |     |        |          |      \n",
      "  They  have      a      microscope\n",
      "\n",
      "\n",
      "Checking sentence: 'He his garden visits'\n",
      "Grammatically incorrect.\n",
      "Corrected sentence: He visits his garden\n",
      "                S                \n",
      "    ____________|___              \n",
      "   |                VP           \n",
      "   |       _________|___          \n",
      "   NP     |             NP       \n",
      "   |      |          ___|____     \n",
      "Pronoun   V        Det       N   \n",
      "   |      |         |        |    \n",
      "   He   visits     his     garden\n",
      "\n",
      "\n",
      "Checking sentence: 'He is cute and he has a violin'\n",
      "Grammatically correct:\n",
      "                      S                                 \n",
      "          ____________|________________                  \n",
      "         |            |                S                \n",
      "         |            |       _________|___              \n",
      "         S            |      |             VP           \n",
      "    _____|___         |      |      _______|___          \n",
      "   NP        VP       |      NP    |           NP       \n",
      "   |      ___|___     |      |     |        ___|____     \n",
      "Pronoun  Be     Adj  Conj Pronoun  V      Det       N   \n",
      "   |     |       |    |      |     |       |        |    \n",
      "   He    is     cute and     he   has      a      violin\n",
      "\n",
      "\n",
      "Checking sentence: 'I am happy my dog with'\n",
      "Grammatically incorrect.\n",
      "Corrected sentence: I am happy with my dog\n",
      "                  S                   \n",
      "          ________|_________           \n",
      "         S                  PP        \n",
      "    _____|___           ____|___       \n",
      "   NP        VP        |        NP    \n",
      "   |      ___|____     |     ___|___   \n",
      "Pronoun  Be      Adj   P   Det      N \n",
      "   |     |        |    |    |       |  \n",
      "   I     am     happy with  my     dog\n",
      "\n",
      "{'Precision': 1.0, 'Recall': 1.0, 'F1-score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "#Evaluate using precision, recall and f1-score\n",
    "def evaluate_predictions(corrected_text, ground_truth):\n",
    "    corrected_tokens = corrected_text.split()\n",
    "    ground_truth_tokens = ground_truth.split()\n",
    "\n",
    "    min_len = min(len(corrected_tokens), len(ground_truth_tokens))\n",
    "    corrected_tokens = corrected_tokens[:min_len]\n",
    "    ground_truth_tokens = ground_truth_tokens[:min_len]\n",
    "\n",
    "    y_true = [1 if ct == gt else 0 for ct, gt in zip(corrected_tokens, ground_truth_tokens)]\n",
    "    y_pred = [1] * len(y_true)\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "    return {\"Precision\": precision, \"Recall\": recall, \"F1-score\": f1}\n",
    "\n",
    "with open(\"test.txt\", \"r\") as file:\n",
    "    test_corpus = file.read()\n",
    "with open(\"ground.txt\", \"r\") as file:\n",
    "    ground_truth = file.read()\n",
    "\n",
    "corrected_corpus = correct_paragraph(test_corpus, word_list, bigram_probabilities, contextual_spell_check)\n",
    "metrics = evaluate_predictions(corrected_corpus, ground_truth)\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
